# LJPW Framework Validation Studies

This directory contains protocols, data, analysis scripts, and results for empirical validation of the LJPW framework.

## Overview

The LJPW framework makes 20+ falsifiable predictions that can be tested through:

- **Randomized Controlled Trials (RCTs)**: Interventions with control groups
- **Observational Studies**: Survey-based measurement across domains
- **Simulation Studies**: Computational validation of dynamics
- **Computational Validation**: Testing coupling coefficients with existing data

## Directory Structure

```
validation-studies/
â”œâ”€â”€ protocols/          # Detailed study protocols
â”‚   â”œâ”€â”€ prediction-02-coupling-coefficients.md
â”‚   â”œâ”€â”€ prediction-04-lw-feedback-loop.md
â”‚   â””â”€â”€ prediction-05-justice-without-love.md
â”œâ”€â”€ data/              # Collected data (empty until studies run)
â”œâ”€â”€ analysis/          # Analysis scripts
â”‚   â”œâ”€â”€ prediction-02-coupling-validation.py
â”‚   â””â”€â”€ prediction-04-lw-feedback-simulation.py
â””â”€â”€ results/           # Results and figures (generated by analysis)
```

## Current Status

### âœ… Completed Protocols

1. **Prediction 2: Coupling Coefficients** (Computational)
   - Protocol: Ready
   - Analysis script: Complete
   - Status: Ready for data collection

2. **Prediction 4: Lâ†”W Feedback Loop** (Simulation + Field)
   - Protocol: Ready
   - Simulation: Complete
   - Status: Simulation validated, ready for field study

3. **Prediction 5: Justice Without Love = Bureaucracy** (Survey)
   - Protocol: Ready
   - Survey instrument: Drafted
   - Status: Ready for pilot testing

### ðŸ”„ In Progress

- None currently (protocols ready, awaiting data collection)

### ðŸ“‹ Planned

- Prediction 1: Love-First Optimization (RCT)
- Prediction 3: Love Singularity Threshold (Longitudinal)
- Predictions 6-20: Various domains and hypotheses

## Study Details

### Prediction 2: Coupling Coefficients

**Hypothesis**: Îº_LJ = 1.4 Â± 0.2 across all domains

**Method**: Measure L, J, and effective_J in 120 systems across 4 domains

**Sample**:
- Software teams (n=30)
- Networks (n=30)
- Organizations (n=30)
- Human-AI collaborations (n=30)

**Analysis**: Linear regression testing Effective_J = J Ã— (1 + Îº_LJ Ã— L)

**Success Criteria**:
- 1.2 < Îº_LJ < 1.6
- RÂ² > 0.6
- p < 0.05
- Cross-domain std < 0.3

**Timeline**: 6 months (data collection: 4 months, analysis: 2 months)

**Script**: `analysis/prediction-02-coupling-validation.py`

**Run**:
```bash
python analysis/prediction-02-coupling-validation.py
# Generates: prediction-02-results.json
```

---

### Prediction 4: Lâ†”W Feedback Loop

**Hypothesis**: Î”W (documentation) â†’ Î”L (collaboration) via Îº_WL = 1.3

**Method**: Documentation intervention (Î”W = +0.4) in 20 undocumented codebases

**Sample**: 20 active codebases (10 open-source, 10 corporate)

**Measurement Timeline**:
- Week 0: Baseline (Lâ‚€, Wâ‚€)
- Weeks 1-2: Documentation sprint
- Week 2: Wâ‚ (immediate)
- Week 4: Lâ‚ (expected Î”L â‰ˆ +0.25)
- Week 6: Lâ‚‚ (sustained effect)

**Analysis**: Paired t-test (Lâ‚ > Lâ‚€) and regression (Î”L ~ Îº_WL Ã— Î”W Ã— Lâ‚€)

**Success Criteria**:
- Î”L > 0.1 (p < 0.05)
- Correlation r > 0.5 (p < 0.05)
- Îº_WL â‰ˆ 1.3 Â± 0.2

**Timeline**: 5 months (recruit: 1 month, intervention: 1 month, follow-up: 2 months, analysis: 1 month)

**Simulation**: `analysis/prediction-04-lw-feedback-simulation.py`

**Run Simulation**:
```bash
python analysis/prediction-04-lw-feedback-simulation.py
# Generates:
#   - prediction-04-field-study-predictions.json
#   - lw-feedback-trajectory.png
```

**Simulation Results**:
- Mean Î”L (Week 4): +0.26 Â± 0.08
- Statistical significance: p < 0.001
- Effect size: Cohen's d > 0.8
- **Ready for field validation**

---

### Prediction 5: Justice Without Love = Bureaucracy

**Hypothesis**: High J + Low L â†’ Lower effective justice than High J + High L

**Method**: Survey 100 organizations, compare groups

**Groups**:
- Group A (High J, Low L): J>0.8, L<0.4 â€” **Bureaucratic**
- Group B (High J, High L): J>0.8, L>0.7 â€” **Effective**
- Group C (Mod J, High L): 0.5<J<0.7, L>0.7 â€” **Collaborative**
- Group D (Other): Control

**Outcomes**:
- Compliance rate (% policies followed)
- Process satisfaction (1-10)
- Bureaucracy index (1-10)

**Predictions**:
- Compliance: Group A < Group B (55% vs. 82%, p<0.05)
- Satisfaction: Group A < Group B (4.2 vs. 8.3, p<0.05)
- Bureaucracy: Group A > Group B (7.5 vs. 2.8, p<0.05)

**Analysis**: ANOVA + regression (Effective_J ~ J + L + JÃ—L)

**Success Criteria**:
- Group B > Group A on all outcomes (p < 0.05)
- Interaction term Î²â‚ƒ > 0 (p < 0.05)
- Effect size: Cohen's d > 0.8

**Timeline**: 7 months (instrument: 1 month, pilot: 1 month, recruit: 2 months, survey: 2 months, analysis: 1 month)

**Protocol**: `protocols/prediction-05-justice-without-love.md`

---

## Running Validation Studies

### Prerequisites

```bash
pip install numpy scipy matplotlib pandas
```

### Quick Start

1. **Run Simulation (Prediction 4)**:
```bash
cd validation-studies/analysis
python prediction-04-lw-feedback-simulation.py
```

2. **Test Coupling Validation (Prediction 2)**:
```bash
cd validation-studies/analysis
python prediction-02-coupling-validation.py
# Uses synthetic data for testing
# Replace with real data: load from CSV
```

3. **View Results**:
```bash
# JSON results
cat prediction-02-results.json
cat prediction-04-field-study-predictions.json

# Figures
open lw-feedback-trajectory.png
```

---

## Data Collection

### For Real Studies (Not Simulations)

1. **Recruit participants**: Target N per protocol
2. **Baseline measurement**: T0 measurements
3. **Intervention** (if RCT): Follow protocol
4. **Follow-up measurements**: T1, T2, ... as specified
5. **Data entry**: Enter into `data/` directory as CSV
6. **Analysis**: Run corresponding Python script
7. **Results**: Save to `results/` directory

### Data Format

**CSV Format** (example: `data/prediction-02-software-teams.csv`):

```csv
team_id,L,J,J_effective,domain
1,0.75,0.80,1.74,software
2,0.82,0.75,1.71,software
...
```

**Load in analysis script**:

```python
import pandas as pd

data = pd.read_csv('../data/prediction-02-software-teams.csv')
L_values = data['L'].values
J_values = data['J'].values
J_effective = data['J_effective'].values
```

---

## Pre-Registration

All studies are **pre-registered** on the Open Science Framework (OSF) before data collection:

- Prediction 2: OSF.io/XXXXX
- Prediction 4: OSF.io/XXXXX
- Prediction 5: OSF.io/XXXXX

Pre-registration includes:
- Hypotheses
- Sample size
- Analysis plan
- Success criteria

This prevents p-hacking and ensures honest reporting.

---

## Open Science Practices

âœ… **Pre-registration**: All protocols registered before data collection

âœ… **Public Data**: All data publicly available (anonymized for privacy)

âœ… **Public Code**: All analysis scripts on GitHub

âœ… **Reproducible**: Complete environment specifications

âœ… **Honest Reporting**: Null results published with same rigor

---

## Publications

Results from these validation studies will be published as:

1. **Paper 2**: "Twenty Falsifiable Predictions of LJPW Framework"
2. **Paper 3-5**: Individual RCT papers
3. **Paper 6**: "Empirical Validation of Coupling Coefficients"

See `../papers/README.md` for publication timeline.

---

## Contributing

To contribute validation data or run studies:

1. **Contact authors**: Request collaboration
2. **Use protocols**: Follow detailed protocols in `protocols/`
3. **Share data**: Submit anonymized data via pull request
4. **Cite studies**: Pre-registration and protocol citations

---

## Contact

For questions about validation studies:

- GitHub Issues: Technical questions
- Email: [Contact info in main README]

---

*Last Updated: November 2025*
*Status: Protocols ready, awaiting data collection*
